{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d36f264",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'ilhan (3.11.9) (Python 3.11.9)' requires the ipykernel package.\n",
      "\u001b[1;31mInstall 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: 'c:/Users/user/Desktop/mlops-dataops-devops-portfolio/ilhan/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22d29c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the cleaned dataset\n",
    "df = pd.read_csv('credit_risk_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a579410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set visualization style\n",
    "#whitegrid make charts easier to read by adding subtle background lines\n",
    "sns.set_theme(style='whitegrid')\n",
    "#create a large figure to hold 4 subplots\n",
    "plt.figure(figsize=(22, 26))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158a73f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target Variable Distrubtion\n",
    "plt.subplot(2, 2, 1) #2 rows 2 columns, position 1 \n",
    "#Countplot shows thee number of observations in each categorical bin\n",
    "sns.countplot(x='loan_status', data=df, palette='viridis')\n",
    "plt.title('Loan Status Distrubtion (o: Paid, 1: Default)', fontsize=14)\n",
    "plt.xlabel('Loan Status')\n",
    "plt.ylabel('Count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8271fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Interest Rate by Loan Grade\n",
    "plt.subplot(2,2,2)\n",
    "#boxplot shows the distribution of quantitative data\n",
    "#order Ensures grades are displayed from A to G\n",
    "sns.boxplot(x='loan_grade', y='loan_int_rate', data=df, order=['A', 'B', 'C', 'D', 'E', 'F', 'G'], palette='coolwarm')\n",
    "plt.title('Interest Rate by Loan Grade', fontsize=14)\n",
    "plt.xlabel('Loan Grade')\n",
    "plt.ylabel('Interest Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59302c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Risk by home ownership\n",
    "plt.subplot(2, 2, 3)\n",
    "#hue='loan_status': Splits the bars by whether they defaulted or not\n",
    "sns.countplot(x='person_home_ownership', hue='loan_status', data=df, palette='Set2')\n",
    "plt.xlabel('Home Ownership')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.legend(title='Status', labels=['0: Paid', '1: Default'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b33de1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Income vs Loan Amount\n",
    "plt.subplot(2, 2, 4)\n",
    "#Scatterplot: Shows relationship between two numeric variables\n",
    "#alpha=0.6: Makes points slightly transparent to see overlaps\n",
    "sns.scatterplot(x='person_income', y='loan_amnt', hue='loan_status', data=df, alpha=0.6, palette='viridis')\n",
    "plt.title('Income vs Loan Amount (Risk Distribution)', fontsize=14)\n",
    "plt.xlabel('Person Income ')\n",
    "plt.ylabel('Loan Amount')\n",
    "#Limit X-axis to 150,000 to ignore extreme high-income outliers and focus on the main group\n",
    "#plt.xlim(0, 150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ea09a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Income vs Loan Amount\n",
    "plt.subplot(2, 2, 4)\n",
    "#Scatterplot: Shows relationship between two numeric variables\n",
    "#alpha=0.6: Makes points slightly transparent to see overlaps\n",
    "sns.scatterplot(x='person_income', y='loan_amnt', hue='loan_status', data=df, alpha=0.6, palette='viridis')\n",
    "plt.title('Income vs Loan Amount (Risk Distribution)', fontsize=14)\n",
    "plt.xlabel('Person Income ')\n",
    "plt.ylabel('Loan Amount')\n",
    "#Limit X-axis to 150,000 to ignore extreme high-income outliers and focus on the main group\n",
    "plt.xlim(0, 150000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07779d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISLPLAY AND SAVE\n",
    "#tight_layout() prevents overlapping texts/titles\n",
    "plt.tight_layout()\n",
    "\n",
    "#Save the plot as a PNG file in your folder\n",
    "plt.savefig('eda_my_analysis.png', dpi=300)\n",
    "\n",
    "#display the plot on the screen \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad38e47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = pd.read_csv('credit_risk_cleaned.csv')\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "# 1. TUVALİ AÇ (Tüm çizimler bu tuvalin içinde olmalı)\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# 2. ÇİZİMLERİ YAP\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.countplot(x='loan_status', data=df, palette='viridis')\n",
    "plt.title('Kredi Durumu')\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "sns.boxplot(x='loan_grade', y='loan_int_rate', data=df, order=['A', 'B', 'C', 'D', 'E', 'F', 'G'])\n",
    "plt.title('Kredi Notu vs Faiz')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.countplot(x='person_home_ownership', hue='loan_status', data=df)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Ev Durumu')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.scatterplot(x='person_income', y='loan_amnt', hue='loan_status', data=df, alpha=0.6)\n",
    "plt.xlim(0, 150000)\n",
    "plt.title('Gelir vs Kredi')\n",
    "\n",
    "# 3. DÜZENLE, KAYDET VE GÖSTER (Sıralama Çok Önemli!)\n",
    "plt.tight_layout() # Yazıların üst üste binmesini engeller\n",
    "plt.savefig('eda_my_analysis_dolu.png', dpi=300) # ÖNCE KAYDET!\n",
    "plt.show() # EN SON EKRANDA GÖSTER VE BELLEĞİ TEMİZLE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e533c3",
   "metadata": {},
   "source": [
    "We have fully digitized the data, making it \"machine-readable.\" However, right before feeding the data into a model (e.g., Logistic Regression or Neural Networks), we must perform two critical mathematical operations. If we skip these, our model will be biased and prone to memorization (overfitting). Here are the last two security checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee07fdd",
   "metadata": {},
   "source": [
    "# Train-Test Split\n",
    "The problem: If we train the model using the entire dataset, we cannot accurately evaluate its true intelligence. It’s like giving a student the exam questions in advance; they memorize them and score 100, but fail in real life.\n",
    "\n",
    "The Solution: We will give 80% of the data to the model and say, \"Learn the rules from this\" (Train). We will hide the remaining 20%. After training, we will test its performance by asking it to predict the outcomes of this unseen 20% (Test)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba6e6d9",
   "metadata": {},
   "source": [
    "# Feature Scaling / Standardization\n",
    "The Problem (Apples and Oranges): In our dataset, the person_income column has massive numbers like 65,000 or 100,000. But the person_age column has small numbers like 22 or 25. Many algorithms (especially KNN, SVM, or Logistic Regression) might mistakenly assume that \"Income is the most important feature simply because its numbers are larger,\" thereby crushing other features.\n",
    "\n",
    "We will compress all numerical columns to the same scale (e.g., standardizing them to have a mean of 0). This ensures a fair competition among features. This is called Standardization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac2e186",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed9059a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#Load the fully encoded data\n",
    "df = pd.read_csv('credit_risk_ready.csv')\n",
    "\n",
    "#Separate features and target \n",
    "#X: all columns EXCPET loan_status\n",
    "\n",
    "X = df.drop('loan_status', axis=1)\n",
    "\n",
    "#y: ONLY the target column\n",
    "y = df['loan_status']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc7951",
   "metadata": {},
   "source": [
    "# TRAIN-TEST SPLIT \n",
    "test_size=0.2: 20% for testing, 80% for training\n",
    "random_state=42: Ensures reproducibility\n",
    "stratify=y: Maintains the class distribution in both sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ebdd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93788340",
   "metadata": {},
   "source": [
    "When we say \"compressing to a mean of 0\" (using StandardScaler), we do not mean making all numbers zero. We are shifting the center of the data.The Logic: The scaler finds the average (mean) of a column and sets that exact average as the new \"0\" point.Example: Imagine the average income of all customers is 60,000 TL. The scaler sets 60,000 as 0.If a customer earns 70,000 TL, their new scaled value becomes a positive number (e.g., +1.2), meaning they are above average.If someone earns 40,000 TL, their value becomes a negative number (e.g., -0.8), meaning they are below average.The Formula: It uses the Z-score formula: $z = \\frac{x - \\mu}{\\sigma}$ (Value minus Mean, divided by Standard Deviation). This ensures that Income, Age, and Interest Rates all speak the same mathematical language (mostly ranging between -3 and +3)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0965ed9",
   "metadata": {},
   "source": [
    "In machine learning, a Pipeline is an automated assembly line. When we use K-Fold Cross Validation, the data is split into multiple train/test chunks over and over again. If we scale the data before this splitting loop, the training data secretly learns the test data's average, causing Data Leakage.\n",
    "\n",
    "When we wrap our scaler and model inside a Pipeline, it acts as a protective shield. In every single fold of the Cross-Validation, the Pipeline automatically asks:\n",
    "\n",
    "\"Did K-Fold just split the data? Yes.\"\n",
    "\n",
    "\"Hide the Test data immediately.\"\n",
    "\n",
    "\"Calculate the StandardScaler ONLY on the current Training data.\"\n",
    "\n",
    "\"Scale the data and train the model.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a256d1",
   "metadata": {},
   "source": [
    "# VERY SIGNIFICANT\n",
    "## Why do we fit the scaler ONLY on the training data\n",
    "### When we set up the scaler, we tell it to \"find the mean value.\" If we scale the entire dataset (Train + Test) together, our model secretly learns the statistical properties (averages) of the Test data during the training phase. This is called Data Leakage, and it creates a falsely high accuracy rate. The golden rule is: Fit on Train, Transform on Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b1ef6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97dc6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#This is the pipeline! It bundles the Scaler and the Model\n",
    "\n",
    "my_pipeline  =Pipeline([\n",
    "\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', RandomForestClassifier(class_weight='balanced', random_state=42))\n",
    "])\n",
    "#Now, instead of passing 'model' to Cross-Validation, we pass 'my_pipeline'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac4802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### STRATIFIED K-FOLD\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "print(\"Running Stratified K-Fold CV on Training Data...\")\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "#!!!!!!!!!!Notice we use X_train and y_train here, NOT X and y !!!!!!!!!!!!!!!!!!!!!!!1\n",
    "cv_results = cross_validate(my_pipeline, X_train, y_train, cv=skf, scoring=('accuracy', 'recall', 'roc_auc'))\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(F\"RESULT OF K-FOLD\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521da530",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#We take the average of the 5 different folds using np.mean()\n",
    "print(f\"Mean Accuracy: % {np.mean(cv_results['test_accuracy']) * 100:.2f}\")\n",
    "\n",
    "#The most important metric in banking! What percentage of actual defaults did we catch?\n",
    "print(f\"Mean Recall: % {np.mean(cv_results['test_recall']) * 100:.2f}\")\n",
    "\n",
    "#The model's overall separation power (anything above 0.80 is considered excellent).\n",
    "print(f\"Mean ROC-AUC Score % {np.mean(cv_results['test_roc_auc']) * 100:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10b2628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#CREATE A DICTIONARY OF MODELS (MODELLER SÖZLÜĞÜ YARAT)\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000, class_weight='balanced'),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(class_weight='balanced', random_state=42),\n",
    "    \"Random Forest\": RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "}\n",
    "\n",
    "#LOOP THROUGH MODELS AND TEST \n",
    "print(\"Starting the Automated Model Arena...\\n\")\n",
    "\n",
    "for name, algorithm in models.items():\n",
    "    \n",
    "    #The pipeline dynamically injects the current 'algorithm' into the 'model' step\n",
    "    current_pipeline = Pipeline([\n",
    "        ('scaler', StandardScaler()),\n",
    "        ('model', algorithm) \n",
    "    ])\n",
    "    \n",
    "    #Run cross-validation for the current pipeline\n",
    "    cv_results = cross_validate(current_pipeline, X_train, y_train, cv=skf, scoring='roc_auc')\n",
    "    \n",
    "    #Print the average ROC-AUC score for this specific model\n",
    "    mean_roc_auc = np.mean(cv_results['test_score']) * 100\n",
    "    \n",
    "    print(f\"Algorithm: {name:20} | Mean ROC-AUC: % {mean_roc_auc:.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Which one is the winner?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e342a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f589c069",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Train the Model (The Magic Happens Here!)\n",
    "print(\"Training the model...\")\n",
    "my_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb50fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Making predictions...\")\n",
    "y_pred = my_pipeline.predict(X_test)\n",
    "#y_pred_proba = my_pipeline.predict_proba(X_test)[:, 1] # Probability of being '1' (Batık olma olasılığı)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c20e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Draw the Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=['0: Paid', '1: Default'], \n",
    "            yticklabels=['0: Paid', '1: Default'])\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix.png')\n",
    "print(\"\\nConfusion Matrix graphic saved as 'confusion_matrix.png'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2e6d5f",
   "metadata": {},
   "source": [
    "The reason you see 1.00 despite having 22 errors is simply rounding. The actual recall is 0.9956, which Python rounds up to 1.00 in the report. Those 22 people are good customers that the bank rejected by mistake, but this is a very small error rate compared to the total number of customers (5094)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d1abf3",
   "metadata": {},
   "source": [
    "# Did the Model Memorize\n",
    "No, it did not overfit! how we do now? because this report is generated from the %20 unseen Test data(the vauşlt we locked earlier) if a model memeorizes the training data, it gets &99 on the train set, but craches to 60%-70% on the unseen test set .Since it maintains a ssolid 93& accuracy and high precision on data it has never seen before, your modle has succesfully learned the underlying rules, not just memeorized the answers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3e4889",
   "metadata": {},
   "source": [
    "# Interpreting the  Metrics for banking\n",
    "Let's look at the numbers row by row. In banking, Class 0 is \"Good Customer\" and Class 1 is \"Defaulter / Bad Customer\n",
    "TP(True Positive = 1 ) catched the bad customer\n",
    "FP(False Positive) \n",
    "FN(False Negative)\n",
    "TN(True Negative)\n",
    "\n",
    "Precision: Out of all the insantces the model predicted as Positive, how many were actually Positive\n",
    "\n",
    "                Precision = TP/ TP + FP\n",
    "Recall: Out of all the actual Positive instances in reality, how many did the model correctly identify\n",
    "\n",
    "                Recall = TP / TP + FN\n",
    "\n",
    "Business Context: High recall means we catch almost all bad guys.\n",
    "\n",
    "f1 Score \n",
    "recall gerçek hayataki verinin ne kadarını doğru bildik sorusunu pozitifler için baktığımızda recall negatif içim baktığımızda Specificity / True Negative Rtae\n",
    "\n",
    "                Specificity = TN / TN + FP\n",
    "\n",
    "Accuracy:The ratio of correctly predicted observations to the total observations\n",
    "\n",
    "\n",
    "                Accuracy = TP + TN / TP + TN + FP + FN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22ed5b5",
   "metadata": {},
   "source": [
    "### The object to use to fit the data. Normally, people pass a simple model here (like LogisticRegression()). However, by passing our my_pipeline, we are giving it a complete \"recipe\" (Scale first, then Train)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566641d3",
   "metadata": {},
   "source": [
    "\n",
    "Random Forest model is very \"conservative\" and acts like a strict perfectionist. It doesn't want to accuse anyone of being a \"defaulter\" unless it is 98% sure (High Precision). But because it requires so much proof, it lets 29% of the sneaky defaulters slip through the cracks (Moderate Recall).\n",
    "\n",
    "For an open-source, baseline ML model, this is a massive success! It is completely ready for the next MLOps phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a81402",
   "metadata": {},
   "source": [
    "# Recall is more important. Because missing a fraud case (False Negative) costs the bank millions of dollars. A false alarm (False Positive / Low Precision) is annoying for the customer, but it doesn't bankrupt the bank."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e7ef567",
   "metadata": {},
   "source": [
    "We will use a library called joblib. It takes your complex my_pipeline object (which contains the StandardScaler math AND the Random Forest trees) and freezes it into a single file on your hard drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977d69d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "#Save the pipeline to a file named credit_risk__model.joblib\n",
    "joblib.dump(my_pipeline, 'credit_risk_model.joblib')\n",
    "print(\"Model saved successfully!\")\n",
    "print(\"credit_risk_model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4f7a43",
   "metadata": {},
   "source": [
    "Now, we will leave Jupyter Notebook.We are going to create a real Python Script.We will use FastAPI, which is the industry standard for high-performance ML APIs\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilhan (3.11.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
